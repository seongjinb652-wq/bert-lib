# bert-lib

# BERT ν•κµ­μ–΄ κ°μ„± λ¶„μ„ & λ‰΄μ¤ ν† ν”½ λ¶„λ¥ νμ΄ν”„λΌμΈ

μ΄ ν”„λ΅μ νΈλ” Hugging Face Transformersμ™€ KLUE/NSMC λ°μ΄ν„°μ…‹μ„ ν™μ©ν•μ—¬  
ν•κµ­μ–΄ κ°μ„± λ¶„μ„ λ° λ‰΄μ¤ ν† ν”½ λ¶„λ¥ λ¨λΈμ„ νμΈνλ‹ν•κ³ ,  
Hub μ—…λ΅λ“ λ° λ¨λΈ μΉ΄λ“ μ‘μ„±κΉμ§€ μ „μ²΄ κ³Όμ •μ„ μ •λ¦¬ν• νμ΄ν”„λΌμΈμ…λ‹λ‹¤.

---

## π“‚ νμΌ κµ¬μ΅° (00 ~ 99)

### 00~09: κΈ°λ³Έ ν™κ²½ λ° μ„¤μ •
- **04_colab_korean_font_setup.py**  
  Colab ν™κ²½μ—μ„ Matplotlib ν•κΈ€ ν°νΈ μ„¤μ • (NanumGothic λ‹¤μ΄λ΅λ“ λ° μ μ©).  
- **05_bert_finetune_pre_eval.py**  
  νμΈνλ‹ μ „ λ¨λΈ μ„±λ¥ ν‰κ°€ (λ² μ΄μ¤λΌμΈ ν™•μΈ).  
- **06_bert_finetune_config.py**  
  TrainingArguments λ° λ©”νΈλ¦­ μ •μ.  
- **07_bert_finetune_train.py**  
  Trainerλ¥Ό μ΄μ©ν• ν•™μµ μ‹¤ν–‰.  
- **08_bert_finetune_metrics.py**  
  ν•™μµ ν›„ λ©”νΈλ¦­ κ³„μ‚° (Accuracy, F1).  
- **09_bert_finetune_eval.py**  
  μµμΆ… ν‰κ°€ λ° μ„±λ¥ ν™•μΈ.  

---

### 70~89: λ°μ΄ν„° μ¤€λΉ„ λ° ν•™μµ
- **79_nsmc_dataset_preprocess_tokenize.py**  
  NSMC λ°μ΄ν„°μ…‹ λ΅λ“, μ „μ²λ¦¬, ν† ν°ν™”, Trainer μ…λ ¥ ν•μ‹ λ³€ν™.  
- **89_bert_sentiment_nsmc_finetune.py**  
  NSMC κ°μ„± λ¶„μ„ λ¨λΈ νμΈνλ‹ λ° ν•™μµ μ „ν›„ μ„±λ¥ ν‰κ°€.  

---

### 90~97: λ¨λΈ μ €μ¥ λ° μ¶”κ°€ λ°μ΄ν„°μ…‹ μ¤€λΉ„
- **97_sentiment_and_topic_model_save_and_ynat.py**  
  NSMC λ¨λΈ μ €μ¥ λ° κ°μ„± λ¶„μ„ ν…μ¤νΈ, KLUE YNAT λ°μ΄ν„°μ…‹ λ΅λ“ λ° νμΈνλ‹ μ¤€λΉ„.  

---

### 98~99: Hub μ—…λ΅λ“ λ° λ¨λΈ μΉ΄λ“
- **98_hub_upload.py**  
  Hugging Face Hub μ—…λ΅λ“ (Trainer μλ™ μ—…λ΅λ“ λ° push_to_hub μλ™ μ—…λ΅λ“ μμ‹).  
- **99_model_card.py**  
  λ¨λΈ μΉ΄λ“(README.md) ν…ν”λ¦Ώ μƒμ„± λ° μ €μ¥.  

---

## π€ μ‹¤ν–‰ μμ„

1. **λ°μ΄ν„° μ¤€λΉ„**  
   - 79 β†’ NSMC λ°μ΄ν„°μ…‹ μ „μ²λ¦¬ λ° ν† ν°ν™”  
2. **λ¨λΈ ν•™μµ**  
   - 89 β†’ NSMC κ°μ„± λ¶„μ„ λ¨λΈ νμΈνλ‹  
3. **λ¨λΈ μ €μ¥ λ° μ¶”κ°€ λ°μ΄ν„°μ…‹ μ¤€λΉ„**  
   - 97 β†’ λ¨λΈ μ €μ¥ λ° YNAT λ°μ΄ν„°μ…‹ μ¤€λΉ„  
4. **Hub μ—…λ΅λ“**  
   - 98 β†’ Hugging Face Hub μ—…λ΅λ“  
5. **λ¨λΈ μΉ΄λ“ μ‘μ„±**  
   - 99 β†’ λ¨λΈ μΉ΄λ“ μƒμ„± λ° μ €μ¥  

---

## π“ κ²°κ³Ό μ”μ•½
- **NSMC κ°μ„± λ¶„μ„**  
  - Accuracy: ~0.89  
  - F1 Score: ~0.89  
- **YNAT λ‰΄μ¤ ν† ν”½ λ¶„λ¥**  
  - 7κ° ν΄λμ¤ λ¶„λ¥ μ¤€λΉ„ μ™„λ£ (μ‹¤ν–‰ μ‹ Trainerλ΅ ν•™μµ κ°€λ¥).  

---

## π“ μ°Έκ³ 
- Hugging Face Hub: [https://huggingface.co](https://huggingface.co)  
- NSMC λ°μ΄ν„°μ…‹: [https://github.com/e9t/nsmc](https://github.com/e9t/nsmc)  
- KLUE YNAT λ°μ΄ν„°μ…‹: [https://huggingface.co/datasets/klue](https://huggingface.co/datasets/klue)  


00~09 ν•μ„ΈνΈ

ν† ν° λ°κΈ‰ μ μ°¨:

""" bash
huggingface.co/settings/tokens μ ‘μ†
"New token" ν΄λ¦­
μ΄λ¦„ μ…λ ¥ λ° κ¶ν• μ„ νƒ (write κ¶ν• ν•„μ”)
ν† ν° λ³µμ‚¬ λ° μ•μ „ν•κ² λ³΄κ΄€
"""

""" 
Library: KoNLP-Finetune
Author: μ„±μ§„
Date: 2026-01-18

Description:
    ν•κµ­μ–΄ μμ—°μ–΄ μ²λ¦¬(NLP) λ¨λΈ νμΈνλ‹ λ° ν‰κ°€λ¥Ό μ„ν• λΌμ΄λΈλ¬λ¦¬.
    Hugging Face Transformers κΈ°λ°μΌλ΅ BERT λ“± μ‚¬μ „ν•™μµ λ¨λΈμ„ λ¶λ¬μ™€
    ν…μ¤νΈ λ¶„λ¥ νƒμ¤ν¬μ— λ§κ² ν•™μµ, ν‰κ°€, νμ΄ν”„λΌμΈ μ‹¤ν–‰μ„ μ§€μ›ν•©λ‹λ‹¤.

Features:
    - λ°μ΄ν„° μ „μ²λ¦¬ λ° ν† ν¬λ‚μ΄μ € μ„¤μ •
    - ν•™μµ/κ²€μ¦ λ°μ΄ν„°μ…‹ κµ¬μ„±
    - Trainer κΈ°λ° ν•™μµ λ° ν‰κ°€
    - Accuracy, F1 λ“± μ£Όμ” λ©”νΈλ¦­ κ³„μ‚°
    - νμΈνλ‹ μ „/ν›„ μ„±λ¥ λΉ„κµ

Dependencies:
    - transformers
    - datasets
    - evaluate
    - numpy
    - matplotlib (μµμ…: μ‹κ°ν™”)

Usage:
    from konlp_finetune import TrainerPipeline

    pipeline = TrainerPipeline(model="bert-base-multilingual-cased")
    pipeline.train(train_data, val_data)
    pipeline.evaluate(test_data)
"""
