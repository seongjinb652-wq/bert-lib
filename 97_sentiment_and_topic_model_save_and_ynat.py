"""
File: sentiment_and_topic_model_save_and_ynat.py
Author: ì„±ì§„
Date: 2026-01-18

Description:
    NSMC ê°ì„± ë¶„ì„ ëª¨ë¸ì„ ë¡œì»¬ì— ì €ì¥í•˜ê³ , ì €ì¥ëœ ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€
    ì˜í™” ë¦¬ë·° ê°ì„± ë¶„ì„ì„ í…ŒìŠ¤íŠ¸í•œ ë’¤ KLUE YNAT ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ì—¬
    ë‰´ìŠ¤ í† í”½ ë¶„ë¥˜ íŒŒì¸íŠœë‹ì„ ì¤€ë¹„í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.

Features:
    - trainer.save_model()ê³¼ tokenizer.save_pretrained()ë¡œ ëª¨ë¸ ì €ì¥
    - ì €ì¥ëœ íŒŒì¼ ëª©ë¡ê³¼ í¬ê¸° í™•ì¸
    - pipelineì„ ì´ìš©í•œ ê°ì„± ë¶„ì„ í…ŒìŠ¤íŠ¸ (ê¸ì •/ë¶€ì •)
    - KLUE YNAT ë°ì´í„°ì…‹ ë¡œë“œ ë° ìƒ˜í”Œ ì¶œë ¥
    - YNAT ë ˆì´ë¸” ì¢…ë¥˜ í™•ì¸ (7ê°œ í† í”½)
    - YNAT íŒŒì¸íŠœë‹ ì½”ë“œ ì˜ˆì‹œ ì œê³µ (ì£¼ì„ ì²˜ë¦¬)

Dependencies:
    - transformers
    - datasets
    - torch
    - os (íŒŒì¼ í™•ì¸ìš©)

Usage:
    $ python 97_sentiment_and_topic_model_save_and_ynat.py
    â†’ ëª¨ë¸ ì €ì¥, ê°ì„± ë¶„ì„ í…ŒìŠ¤íŠ¸, YNAT ë°ì´í„°ì…‹ ì¤€ë¹„ ê³¼ì •ì„ ì‹¤í–‰

Note:
    - YNAT íŒŒì¸íŠœë‹ ì½”ë“œëŠ” ì£¼ì„ ì²˜ë¦¬ë˜ì–´ ìˆìœ¼ë©°, ì‹¤ì œ í•™ìŠµ ì‹œ ì£¼ì„ì„ í•´ì œí•´ì•¼ í•¨
    - ì €ì¥ëœ ëª¨ë¸ì€ ì´í›„ Hub ì—…ë¡œë“œë‚˜ ì¶”ê°€ íŒŒì¸íŠœë‹ì— í™œìš© ê°€ëŠ¥
"""
# ëª¨ë¸ ì €ì¥
save_path = "./my-nsmc-model"
trainer.save_model(save_path)
tokenizer.save_pretrained(save_path)

print(f"âœ… ëª¨ë¸ì´ '{save_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

# ì €ì¥ëœ íŒŒì¼ í™•ì¸
import os

files = os.listdir(save_path)
print(f"\nğŸ“ ì €ì¥ëœ íŒŒì¼ë“¤:")
for f in files:
    size = os.path.getsize(os.path.join(save_path, f))
    print(
        f"   {f}: {size / 1024 / 1024:.1f} MB"
        if size > 1024 * 1024
        else f"   {f}: {size / 1024:.1f} KB"
    )    from transformers import pipeline

# ì €ì¥ëœ ëª¨ë¸ë¡œ pipeline ìƒì„±
my_classifier = pipeline("sentiment-analysis", model=save_path, tokenizer=save_path)

# í…ŒìŠ¤íŠ¸!
test_reviews = [
    "ì´ ì˜í™” ì§„ì§œ ìµœê³ ì˜ˆìš”! ê°ë™ë°›ì•˜ìŠµë‹ˆë‹¤.",
    "ì‹œê°„ ë‚­ë¹„í–ˆë„¤ìš”. ë³„ë¡œì…ë‹ˆë‹¤.",
    "ê·¸ëƒ¥ ê·¸ë˜ìš”. í‰ë²”í•œ ì˜í™”ì…ë‹ˆë‹¤.",
    "ë°°ìš° ì—°ê¸°ê°€ ì •ë§ ì¸ìƒì ì´ì—ˆì–´ìš”!",
    "ìŠ¤í† ë¦¬ê°€ ë„ˆë¬´ ì§€ë£¨í–ˆì–´ìš”.",
]

print("ğŸ¬ ì˜í™” ë¦¬ë·° ê°ì„± ë¶„ì„ ê²°ê³¼:")
print("-" * 50)
for review in test_reviews:
    result = my_classifier(review)[0]
    emoji = "ğŸ˜Š" if result["label"] == "ê¸ì •" else "ğŸ˜ "
    print(f"{emoji} {review[:25]}...")
    print(f"   â†’ {result['label']} ({result['score']:.2%})")
    print()     # KLUE YNAT ë°ì´í„°ì…‹ ë¡œë“œ
ynat_datasets = load_dataset("klue", "ynat")

print("ğŸ“° YNAT ë°ì´í„°ì…‹ (ë‰´ìŠ¤ í† í”½ ë¶„ë¥˜):")
print(f"   í•™ìŠµ ë°ì´í„°: {len(ynat_datasets['train']):,}ê°œ")
print(f"   ê²€ì¦ ë°ì´í„°: {len(ynat_datasets['validation']):,}ê°œ")

# ìƒ˜í”Œ í™•ì¸
sample = ynat_datasets["train"][0]
print(f"\nğŸ“ ìƒ˜í”Œ:")
print(f"   ì œëª©: {sample['title']}")
print(f"   ë ˆì´ë¸”: {sample['label']}")

# ë ˆì´ë¸” ì¢…ë¥˜ í™•ì¸
label_names = ["IT/ê³¼í•™", "ê²½ì œ", "ì‚¬íšŒ", "ìƒí™œë¬¸í™”", "ì„¸ê³„", "ìŠ¤í¬ì¸ ", "ì •ì¹˜"]
print(f"\nğŸ·ï¸ 7ê°œ í† í”½: {label_names}"  # YNAT íŒŒì¸íŠœë‹ ì½”ë“œ (ì‹¤í–‰ì€ ì£¼ì„ ì²˜ë¦¬)
"""
# í† í°í™” í•¨ìˆ˜
def tokenize_ynat(examples):
    return tokenizer(
        examples["title"],
        padding="max_length",
        truncation=True,
        max_length=64
    )

# ì „ì²˜ë¦¬
tokenized_ynat = ynat_datasets.map(tokenize_ynat, batched=True)
tokenized_ynat = tokenized_ynat.remove_columns(["guid", "title", "url", "date"])
tokenized_ynat = tokenized_ynat.rename_column("label", "labels")
tokenized_ynat.set_format("torch")

# ëª¨ë¸ (7ê°œ í´ë˜ìŠ¤)
ynat_model = AutoModelForSequenceClassification.from_pretrained(
    checkpoint,
    num_labels=7
)

# Trainer
ynat_trainer = Trainer(
    model=ynat_model,
    args=TrainingArguments(
        output_dir="./ynat-finetuned",
        num_train_epochs=3,
        per_device_train_batch_size=32,
        evaluation_strategy="epoch"
    ),
    train_dataset=tokenized_ynat["train"],
    eval_dataset=tokenized_ynat["validation"],
    compute_metrics=compute_metrics
)

# í•™ìŠµ
ynat_trainer.train()
"""

print("ğŸ’¡ YNAT íŒŒì¸íŠœë‹ ì½”ë“œê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
print("   ì‹¤ì œ ì‹¤í–‰í•˜ë ¤ë©´ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”!") 
