"""
File: bert_finetune_pre_eval.py
Author: μ„±μ§„
Date: 2026-01-18

Description:
    Hugging Face Transformersμ AutoModelForSequenceClassificationμ„ ν™μ©ν•μ—¬
    νμΈνλ‹ μ „ ν…μ¤νΈ λ¶„λ¥ λ¨λΈμ μ„±λ¥μ„ ν‰κ°€ν•λ” μμ  μ½”λ“μ…λ‹λ‹¤.

Features:
    - raw λ°μ΄ν„°μ…‹μ—μ„ λΌλ²¨ μ΄λ¦„ μ¶”μ¶
    - id2label, label2id λ§¤ν•‘ μƒμ„±
    - νμΈνλ‹ μ „ λ¨λΈμ„ pipelineμΌλ΅ λ΅λ“
    - ν…μ¤νΈ μƒν”μ— λ€ν•΄ μμΈ΅ μν–‰ λ° μ •ν™•λ„ κ³„μ‚°
    - λλ¤ μ΄κΈ°ν™”λ λ¶„λ¥ ν—¤λ“λ΅ μΈν•΄ λ‚®μ€ μ„±λ¥ ν™•μΈ

Dependencies:
    - transformers (AutoModelForSequenceClassification, pipeline)
    - datasets (raw λ°μ΄ν„°μ…‹)
    - numpy (argmax λ“± ν•„μ” μ‹)

Usage:
    1. μ²΄ν¬ν¬μΈνΈμ™€ ν† ν¬λ‚μ΄μ €λ¥Ό μ¤€λΉ„
    2. λ³Έ μ¤ν¬λ¦½νΈλ¥Ό μ‹¤ν–‰ν•λ©΄ νμΈνλ‹ μ „ λ¨λΈμ μμΈ΅ κ²°κ³Όμ™€ μ •ν™•λ„κ°€ μ¶λ ¥λ¨
    3. μ„±λ¥μ€ λλ¤ μμ¤€μ— κ°€κΉμ°λ©°, νμΈνλ‹ ν•„μ”μ„±μ„ ν™•μΈ κ°€λ¥

Note:
    - μ¶λ ¥λ μ •ν™•λ„λ” λ² μ΄μ¤λΌμΈ μ„±λ¥μΌλ΅, μ΄ν›„ νμΈνλ‹ ν›„ μ„±λ¥κ³Ό λΉ„κµν•λ” λ° ν™μ©
"""

#  raw['train'].features['label'].namesμ—μ„ λΌλ²¨ μ΄λ¦„ μ¶”μ¶ κ°€λ¥
# label_names = _______________
label_names = raw['train'].features['label'].names

# μ«μ β†’ λΌλ²¨ μ΄λ¦„
id2label = {i: n for i, n in enumerate(label_names)}

# λΌλ²¨ μ΄λ¦„ β†’ μ«μ
label2id = {n: i for i, n in enumerate(label_names)}

print("λΌλ²¨ λ©λ΅:", label_names)
print("id2label:", id2label

model = AutoModelForSequenceClassification.from_pretrained(
    checkpoint ,         # μ²΄ν¬ν¬μΈνΈ
    num_labels=len(label_names),  # λ¶„λ¥ν•  ν΄λμ¤ μ
    id2label=id2label,    # μ«μ β†’ λΌλ²¨
    label2id=label2id     # λΌλ²¨ β†’ μ«μ
)

from transformers import pipeline

# νμΈνλ‹ μ „ λ¨λΈλ΅ pipeline μƒμ„±
classifier_before = pipeline('text-classification', model=model, tokenizer=tokenizer)

# ν…μ¤νΈν•  λ‰΄μ¤ μ λ©λ“¤ (μ •λ‹µ ν¬ν•¨)
test_samples = [
    ("μ‚Όμ„±μ „μ, μ‹ ν• κ°¤λ­μ‹ μ‹λ¦¬μ¦ κ³µκ°", "ITκ³Όν•™"),
    ("μ½”μ¤ν”Ό μ¥μ¤‘ 3000μ„  λν", "κ²½μ "),
    ("μ†ν¥λ―Ό, μ‹μ¦ 15νΈκ³¨ ν­λ°", "μ¤ν¬μΈ "),
    ("μ—¬μ•Ό, μμ‚°μ• μ²λ¦¬ λ‘κ³  μ¶©λ", "μ •μΉ"),
    ("μ „κµ­ λ―Έμ„Έλ¨Όμ§€ 'λ‚μ¨'...μ™Έμ¶ μμ ", "μ‚¬ν"),
]

print("=" * 60)
print("π”΄ νμΈνλ‹ μ „ λ¨λΈ μμΈ΅ κ²°κ³Ό")
print("=" * 60)
print("\nβ οΈ  λ¶„λ¥ ν—¤λ“κ°€ λλ¤ μ΄κΈ°ν™” μƒνƒμ΄λ―€λ΅ μμΈ΅μ΄ λ¶€μ •ν™•ν•©λ‹λ‹¤!\n")

correct = 0
for title, true_label in test_samples:
    result = classifier_before(title)[0]
    is_correct = result['label'] == true_label
    correct += is_correct
    status = "β…" if is_correct else "β"

    print(f"μ λ©: {title}")
    print(f"  μ •λ‹µ: {true_label}")
    print(f"  μμΈ΅: {result['label']} (μ‹ λΆ°λ„: {result['score']:.2%}) {status}")
    print()

print(f"μ •ν™•λ„: {correct}/{len(test_samples)} ({correct/len(test_samples)*100:.1f}%)")
print("\nβ†’ λλ¤ μμ¤€(μ•½ 14.3% = 1/7)μ— κ°€κΉμ΄ μ„±λ¥!")
